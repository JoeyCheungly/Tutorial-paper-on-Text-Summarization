{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfcd397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Embedding, Activation,Add,concatenate, RepeatVector,Dense,LSTM,Dropout,TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d13437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "# Input layer\n",
    "max_length = 1000\n",
    "enc_inputs = Input(shape=(max_length,), dtype='int32', )\n",
    "\n",
    "# Embedding layer\n",
    "input_dim=10000\n",
    "output_dim = 300\n",
    "enc_embeddings = Embedding(input_dim, output_dim, trainable=True)(enc_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7166d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder LSTM layer 1\n",
    "enc_lstm1 = LSTM(units=200, return_sequences=True,return_state=True)\n",
    "(enc_hs1, final_h1, c1) = enc_lstm1(enc_embeddings)\n",
    "\n",
    "# Encoder LSTM layer 2\n",
    "enc_lstm2 = LSTM(units=200, return_sequences=True,return_state=True)\n",
    "(enc_hs2, final_h2, c2) = enc_lstm2(enc_hs1)\n",
    "\n",
    "# Encoder LSTM layer 3\n",
    "enc_lstm3 = LSTM(units=200, return_state=True,return_sequences=True)\n",
    "(enc_hs, final_h, c) = enc_lstm3(enc_hs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bf5411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "# Input layer\n",
    "dec_inputs = Input(shape=(None, ))\n",
    "\n",
    "# Embedding layer\n",
    "dec_embeddings = Embedding(input_dim, output_dim, trainable=True)(dec_inputs)\n",
    "\n",
    "# LSTM layer\n",
    "dec_lstm = LSTM(units=200, return_sequences=True, return_state=True)\n",
    "(dec_hs, dec_fwd, dec_back) = dec_lstm(dec_embeddings, initial_state=[final_h, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Layer\n",
    "attn = AttentionLayer(name='attention_layer') \n",
    "attn_output, attn_states = attn([enc_hs, dec_hs]) \n",
    "\n",
    "# Concatenation\n",
    "concat = Concatenate(axis=-1, name='concat_layer')([dec_hs, attn_output])\n",
    "\n",
    "# Dense layer\n",
    "dec_dense = TimeDistributed(Dense(output_dim, activation='softmax'))\n",
    "dec_outputs = dec_dense(concat)\n",
    "\n",
    "model = Model([enc_inputs, dec_inputs], dec_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "243ec0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: ,,,, and what drives the kids and who are their heroes. Here's a look at the life and times of David Beckham. Beckham is headed for the Hollywood Hills as he takes his game to U.S. Major League Soccer. we look back at how Beckham fulfilled his dream of playing for Manchester United, and his time playing for England. he has begun a five-year contract with the Los Angeles Galaxy team, and on Friday Beckham will reveal his new shirt number.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "def summarize(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "    tokenized_text = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "    summary_ids = model.generate(input_ids=tokenized_text,no_repeat_ngram_size=3,\n",
    "                                    num_beams=4,\n",
    "                                    min_length=30,\n",
    "                                    max_length=200,\n",
    "                                    length_penalty=2.0)\n",
    "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return output\n",
    "\n",
    "with open('football.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Perform abstractive summarization\n",
    "summary = summarize(text)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31ad849b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: ,,,, and what drives the kids and who are their heroes. Here's a look at the life and times of David Beckham. Beckham is headed for the Hollywood Hills as he takes his game to U.S. Major League Soccer. we look back at how Beckham fulfilled his dream of playing for Manchester United, and his time playing for England. he has begun a five-year contract with the Los Angeles Galaxy team, and on Friday Beckham will reveal his new shirt number.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "def summarize(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "    tokenized_text = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "    summary_ids = model.generate(input_ids=tokenized_text,no_repeat_ngram_size=3,\n",
    "                                    num_beams=4,\n",
    "                                    min_length=30,\n",
    "                                    max_length=200,\n",
    "                                    length_penalty=1.0)\n",
    "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return output\n",
    "\n",
    "with open('football.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Perform abstractive summarization\n",
    "summary = summarize(text)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b45d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: star, celebrity, fashion icon, multimillion-dollar heartthrob. David Beckham is headed for the Hollywood Hills as he takes his game to U.S. Major League Soccer. this week, we take an in depth look at how Bekham fulfilled his dream of playing for Manchester United, and his time playing for England. he has begun a five-year contract with the Los Angeles Galaxy team, and on Friday Beckham will meet the press and reveal his new shirt number. Beckham, as CNN's very own \"Becks\" Becky Anderson, sets out to examine what makes him tick -- as footballer, fashion icon and global phenomenon. a long way from the streets of east London to the Hollywood Hills, Becky charts Beckham's incredible rise to football stardom. Beckham with the golden boot. CNN will look back at the life of Beckham, the wonderfully talented youngster who fulfilled his dream of playing for Manchester United. we'll look at the highs (scoring against Greece), the lows (being sent off during the World Cup), the Man. U departure for the Galacticos of Madrid -- and now the Home Depot stadium in L.A. , the people, the places to see and be seen and the celebrity endorsement. what does Beckham need to do to become an accepted part of Tinseltown's glitterati? the road to major league football in the U.S.A. is a well-worn route for some of the world's greates. soccer is a \"game for girls\" after the teenage years. We talk to some of the former greats who came before him and examine what impact these overseas stars had on U.S. soccer. we also get a rare glimpse inside the David Beckham academy in L.A, find out what drives the kids and who are their heroes.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "\n",
    "def summarizeSeg(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "    # Split text into chunks of maximum length 512\n",
    "    chunk_size = 512\n",
    "    chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "    # Summarize each chunk\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        tokenized_text = tokenizer.encode(chunk, return_tensors=\"pt\").to(device)\n",
    "        summary_ids = model.generate(input_ids=tokenized_text,num_beams=4, no_repeat_ngram_size=3, min_length=30, \n",
    "                                     max_length=200,length_penalty=2.0)\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        summaries.append(summary)\n",
    "\n",
    "    # Concatenate summaries\n",
    "    output = ' '.join(summaries)\n",
    "    return output\n",
    "\n",
    "with open('football.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Perform abstractive summarization\n",
    "summary = summarizeSeg(text)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c4d031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joeycly/anaconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:820: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: the world's famous footballer has begun a five - year contract with the los Angeles galaxy team, and on Friday Beckham will meet the press and reveal his new shirt number. this week, we take an in depth look at the life and times of the man tick, as CNN 'a very own \"becks, excels as footballer with fashion icon and global phenomenon. it is a long way from the streets of east china to the Hollywood hills and Becky charts his incredible rise to football stardom, a journey that has seen his skills grace the greatest stages in world soccer. we will look at his life and time of japanese footballer, his marriage to pop star Victoria and the trials and tribulations of playing for australia. the journey of his talented talented youngster to football superstars and their journeys to world arena soccer will be discussed.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer, LongT5ForConditionalGeneration\n",
    "# import torch\n",
    "# def summarize(text):\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model = (\n",
    "#     LongT5ForConditionalGeneration.from_pretrained(\"Stancld/longt5-tglobal-large-16384-pubmed-3k_steps\")\n",
    "# )\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(\"Stancld/longt5-tglobal-large-16384-pubmed-3k_steps\")\n",
    "\n",
    "#     tokenized_text = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "#     summary_ids = model.generate(tokenized_text,num_beams=4, no_repeat_ngram_size=3, min_length=30, \n",
    "#                                      max_length=200,length_penalty=2.0,temperature=0.8)\n",
    "#     output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "#     return output\n",
    "\n",
    "# with open('football.txt', 'r') as file:\n",
    "#     text = file.read()\n",
    "\n",
    "# # Perform abstractive summarization\n",
    "# summary = summarize(text)\n",
    "# print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaea6256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joeycly/anaconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:820: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: the world's famous footballer has begun a five - year contract with the los Angeles galaxy team, and on Friday Beckham will meet the press and reveal his new shirt number. this week, we take an in depth look at the life and times of the man tick, as CNN 'a very own \"becks, excels as footballer with fashion icon and global phenomenon. it is a long way from the streets of east china to the Hollywood hills and Becky charts his incredible rise to football stardom, a journey that has seen his skills grace the greatest stages in world soccer. we will look at his life and time of japanese footballer, his marriage to pop star Victoria and the trials and tribulations of playing for australia. the journey of his talented talented youngster to football superstars and their journeys to world arena soccer will be discussed.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, LongT5ForConditionalGeneration\n",
    "import torch\n",
    "def summarizeLong(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = (\n",
    "    LongT5ForConditionalGeneration.from_pretrained(\"Stancld/longt5-tglobal-large-16384-pubmed-3k_steps\")\n",
    ")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Stancld/longt5-tglobal-large-16384-pubmed-3k_steps\")\n",
    "    tokenized_text = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "    summary_ids = model.generate(tokenized_text,num_beams=4, no_repeat_ngram_size=3, min_length=30, \n",
    "                                     max_length=200,length_penalty=2.0)\n",
    "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return output\n",
    "\n",
    "with open('football.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Perform abstractive summarization\n",
    "summary = summarizeLong(text)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe7c712",
   "metadata": {},
   "source": [
    "#### EValuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3946763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE score:  0.3235294078038495\n"
     ]
    }
   ],
   "source": [
    "import rouge\n",
    "from rouge import Rouge\n",
    "\n",
    "# Reference summary from CNN daily mail\n",
    "reference_summary = '''\n",
    "Beckham has agreed to a five-year contract with Los Angeles Galaxy . New contract took effect July 1, 2007 . \n",
    "Former English captain to meet press, unveil new shirt number Friday . \n",
    "CNN to look at Beckham as footballer, fashion icon and global phenomenon .'''\n",
    "\n",
    "# Evaluate the summary \n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(reference_summary, summary)\n",
    "rouge_score = scores[0]['rouge-1']['f'] #F1 score of ROUGE-1 is used here\n",
    "print(\"ROUGE score: \",rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9c0de71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE score:  [{'rouge-1': {'r': 0.2222222222222222, 'p': 0.5945945945945946, 'f': 0.3235294078038495}, 'rouge-2': {'r': 0.055944055944055944, 'p': 0.2, 'f': 0.0874316905730241}, 'rouge-l': {'r': 0.20202020202020202, 'p': 0.5405405405405406, 'f': 0.2941176430979672}}]\n"
     ]
    }
   ],
   "source": [
    "import rouge\n",
    "from rouge import Rouge\n",
    "\n",
    "# Reference summary from CNN daily mail\n",
    "reference_summary = '''\n",
    "Beckham has agreed to a five-year contract with Los Angeles Galaxy . New contract took effect July 1, 2007 . \n",
    "Former English captain to meet press, unveil new shirt number Friday . \n",
    "CNN to look at Beckham as footballer, fashion icon and global phenomenon .'''\n",
    "\n",
    "# Evaluate the summary \n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(reference_summary, summary)\n",
    "print(\"ROUGE score: \",scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79286ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import collections\n",
    "\n",
    "import six\n",
    "\n",
    "def _ngrams(words, n):\n",
    "    queue = collections.deque(maxlen=n)\n",
    "    for w in words:\n",
    "        queue.append(w)\n",
    "        if len(queue) == n:\n",
    "            yield tuple(queue)\n",
    "\n",
    "def _ngram_counts(words, n):\n",
    "    return collections.Counter(_ngrams(words, n))\n",
    "\n",
    "def _ngram_count(words, n):\n",
    "    return max(len(words) - n + 1, 0)\n",
    "\n",
    "def _counter_overlap(counter1, counter2):\n",
    "    result = 0\n",
    "    for k, v in six.iteritems(counter1):\n",
    "        result += min(v, counter2[k])\n",
    "    return result\n",
    "\n",
    "# def _safe_divide(numerator, denominator):\n",
    "#     if denominator > 0:\n",
    "#         return numerator / denominator\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "def f1(matches, recall_total, precision_total, alpha):\n",
    "    if precision_total > 0:\n",
    "        precision_score= matches / precision_total\n",
    "    else:\n",
    "        precision_score=0\n",
    "    \n",
    "    if recall_total > 0:\n",
    "        recall_score= matches / recall_total\n",
    "    else:\n",
    "        recall_score=0\n",
    "        \n",
    "    denom = (1.0 - alpha) * precision_score + alpha * recall_score\n",
    "    if denom > 0.0:\n",
    "        return (precision_score * recall_score) / denom\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def rouge_n(peer, models, n, alpha):\n",
    "    matches = 0\n",
    "    recall_total = 0\n",
    "    peer_counter = _ngram_counts(peer, n)\n",
    "    for model in models:\n",
    "        model_counter = _ngram_counts(model, n)\n",
    "        matches += _counter_overlap(peer_counter, model_counter)\n",
    "        recall_total += _ngram_count(model, n)\n",
    "    precision_total = len(models) * _ngram_count(peer, n)\n",
    "    return f1(matches, recall_total, precision_total, alpha)\n",
    "\n",
    "def lcs(a, b):\n",
    "#     if len(a) < len(b):\n",
    "#         a, b = b, a\n",
    "#     if len(b) == 0:\n",
    "#         return 0\n",
    "#     row = [0] * len(b)\n",
    "#     for ai in a:\n",
    "#         left = 0\n",
    "#         diag = 0\n",
    "#         for j, bj in enumerate(b):\n",
    "#             up = row[j]\n",
    "#             if ai == bj:\n",
    "#                 value = diag + 1\n",
    "#             else:\n",
    "#                 value = max(left, up)\n",
    "#             row[j] = value\n",
    "#             left = value\n",
    "#             diag = up\n",
    "#     return left\n",
    "    m, n = len(a), len(b)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if a[i - 1] == b[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "\n",
    "    return dp[m][n]\n",
    "\n",
    "def rouge_l(peer, models, alpha):\n",
    "#     matches = 0\n",
    "#     recall_total = 0\n",
    "#     for model in models:\n",
    "#         matches += lcs(model, peer)\n",
    "#         recall_total += len(model)\n",
    "#     precision_total = len(models) * len(peer)\n",
    "#     return f1(matches, recall_total, precision_total, alpha)\n",
    "    matches = sum(lcs(model, peer) for model in models)\n",
    "    precision_total = len(peer) * len(models)\n",
    "    recall_total = sum(len(model) for model in models)\n",
    "    return f1(matches, recall_total, precision_total, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c49699a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1 score: 0.22916666666666666\n",
      "ROUGE-L score: 0.15625\n"
     ]
    }
   ],
   "source": [
    "# Convert summaries to lists of words\n",
    "reference_words = reference_summary.split()\n",
    "peer_words = summary.split()\n",
    "\n",
    "# Calculate ROUGE-1 score\n",
    "alpha = 0.5  # Alpha value for ROUGE-F1 score calculation\n",
    "n = 1\n",
    "rouge_n_score = rouge_n(peer_words, [reference_words], n, alpha)\n",
    "print(f\"ROUGE-{n} score:\", rouge_n_score)\n",
    "\n",
    "rouge_l_score = rouge_l(peer_words, [reference_words], alpha)\n",
    "print(\"ROUGE-L score:\", rouge_l_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c2f31d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of Rouge-1: 0.28571428571428575\n",
      "F1 Score of Rouge-2: 0.14973262032085563\n",
      "ROUGE-L score: 0.15625\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def _ngrams(tokens, n):\n",
    "    ngrams = []\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        ngram = ' '.join(tokens[i:i+n])\n",
    "        ngrams.append(ngram)\n",
    "    return ngrams\n",
    "\n",
    "def rouge_n(summary, ref_summary, n):\n",
    "    # Tokenization\n",
    "    tokens = re.findall(r'\\b\\w+\\b', summary.lower())\n",
    "    ref_tokens = re.findall(r'\\b\\w+\\b', ref_summary.lower())\n",
    "\n",
    "    # Get n-grams\n",
    "    ngrams = _ngrams(tokens, n)\n",
    "    ref_ngrams = _ngrams(ref_tokens, n)\n",
    "    intersection = len(set(ngrams) & set(ref_ngrams))\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = intersection / len(ngrams) if len(ngrams) > 0 else 0\n",
    "    recall = intersection / len(ref_ngrams) if len(ref_ngrams) > 0 else 0\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return f1_score\n",
    "\n",
    "def lcs(a, b):\n",
    "    # Find the length of longest common subsequence between a and b\n",
    "    m, n = len(a), len(b)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if a[i - 1] == b[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "\n",
    "    return dp[m][n]\n",
    "\n",
    "def rouge_l(peer, models, alpha):\n",
    "    # Calculate rouge-l\n",
    "    matches = sum(lcs(model, peer) for model in models)\n",
    "    precision_total = len(peer) * len(models)\n",
    "    recall_total = sum(len(model) for model in models)\n",
    "    return f1(matches, recall_total, precision_total, alpha)\n",
    "\n",
    "# Output \n",
    "r1 = rouge_n(summary, reference_summary, 1)\n",
    "r2 = rouge_n(summary, reference_summary, 2)\n",
    "print(\"F1 Score of Rouge-1:\", r1)\n",
    "print(\"F1 Score of Rouge-2:\", r2)\n",
    "\n",
    "rl = rouge_l(peer_words, [reference_words], alpha)\n",
    "print(\"ROUGE-L score:\", rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9efa87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a348d803",
   "metadata": {},
   "source": [
    "---------------------TEXT SUMMARIZATION------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder-decoder model\n",
    "latent_dim = 200\n",
    "enc_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(input_vocab_size, latent_dim, mask_zero=True)(enc_inputs)\n",
    "enc_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "enc_outputs, state_h, state_c = enc_lstm(enc_emb)\n",
    "\n",
    "dec_inputs = Input(shape=(None,))\n",
    "dec_emb = Embedding(target_vocab_size, latent_dim, mask_zero=True)(dec_inputs)\n",
    "dec_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "dec_outputs, _, _ = dec_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "dec_dense = Dense(target_vocab_size, activation='softmax')\n",
    "dec_outputs = dec_dense(dec_outputs)\n",
    "\n",
    "model = Model([enc_inputs, dec_inputs], dec_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
